<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.18" />
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>More than seven &middot; More than seven</title>

  
  <link rel="stylesheet" href="/css/poole.css">
  <link rel="stylesheet" href="/css/hyde.css">
  <link rel="stylesheet" href="/css/poole-overrides.css">
  <link rel="stylesheet" href="/css/hyde-overrides.css">
  <link rel="stylesheet" href="/css/hyde-x.css">
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/touch-icon-144-precomposed.png">
  <link href="/favicon.png" rel="icon">

  
  
  
  <link href="/index.xml" rel="alternate" type="application/rss+xml" title="More than seven &middot; More than seven" />

  <meta name="description" content="">
  <meta name="keywords" content="">
  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-435455-1', 'auto');
    ga('send', 'pageview');
  </script>
  
</head>
<body class="theme-base-08">
<div class="sidebar">
  <script async type="text/javascript" src="//cdn.carbonads.com/carbon.js?zoneid=1673&serve=C6AILKT&placement=morethansevennet" id="_carbonads_js"></script>
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      
      <h1><a href="/">More than seven</a></h1>
      <p class="lead">Writing about code. Occasional other topics. Made by <a href="https://twitter.com/garethr">@garethr</a>.</p>
    </div>
  </div>
</div>


<div class="content container">
  <div class="posts">
    
    
    <div class="post">
      <h1 class="post-title">
        <a href="/2015/12/27/operations-more-than-systems-administration/">Operations is more than just Systems Administration</a>
      </h1>
      <span class="post-date">Dec 27, 2015 &middot; 4 minute read
      </span>
      
      

<p>I think one of the patterns of the last few years has been the
democratization of systems administration, especially for web
applications. Whether that&rsquo;s Heroku or Docker, or Chef or Puppet, more
and more traditional developers are doing work that would have been
<em>somebody else&rsquo;s problem</em> only a few years ago. But running in parallel
to that thread is another less positive trend, that of conflating
operations with <em>just</em> systems administation. The story seems to go that
now we know Ansible (or some other tool) we just need developers to run
the show.</p>

<p>In this post I&rsquo;m going to try and introduce some of the other
operational disciplines, especially for developers who maybe have come
to operations via the above resurgence in infrastructure tooling over
the past few years.</p>

<p>Note that this post has a slight bias towards more <em>normal</em>
organisations. That is to say if you&rsquo;re in a 5 person software startup
you probably don&rsquo;t have operational problems to worry too much about
yet. I&rsquo;m also not playing down the practice of systems administration,
most experienced sysadmins I know are also quite rounded operations pros
as well.</p>

<h2 id="service-management">Service Management</h2>

<p>If you&rsquo;ve worked in operations, or in many large organisations you&rsquo;ll have
come across the term Service Management. This tends to be linked to
various service management frameworks; like ITIL or MOF (Microsoft
Operations Framework). The framework will describe, often in great
detail, activities and processes for things like incident response,
configuration management, change management, capacity planning and more.</p>

<p>While I was at <a href="https://gds.blog.gov.uk/">The Government</a> I wrote what I
think is a reasonable introduction to <a href="https://www.gov.uk/service-manual/operations/service-management.html">Service
Management</a>
albeit from a specific point-of-view. This was based on my experience of
trying, and likely sometimes failing, to encourage teams to think about
how the products they we&rsquo;re working on would be run. Each of the topics
touched on in the overview is worthy of it&rsquo;s own stack of books, but I
will repeat the ITIL service list here as (whatever you might think of
the framework or a specific implementation) I&rsquo;d found it a useful starting
point for conversations - in particular stressing the breadth of
topics under service management.</p>

<h4 id="service-strategy">Service Strategy</h4>

<ul>
<li>IT service management</li>
<li>Service portfolio management</li>
<li>Financial management for IT services</li>
<li>Demand management</li>
<li>Business relationship management</li>
</ul>

<h3 id="service-design">Service Design</h3>

<ul>
<li>Design coordination</li>
<li>Service Catalogue management</li>
<li>Service level management</li>
<li>Availability management</li>
<li>Capacity Management</li>
<li>IT service continuity management</li>
<li>Information security management system</li>
<li>Supplier management</li>
</ul>

<h3 id="service-transition">Service Transition</h3>

<ul>
<li>Transition planning and support</li>
<li>Change management</li>
<li>Service asset and configuration management</li>
<li>Release and deployment management</li>
<li>Service validation and testing</li>
<li>Change evaluation</li>
<li>Knowledge management</li>
</ul>

<h3 id="service-operation">Service Operation</h3>

<ul>
<li>Event management</li>
<li>Incident management</li>
<li>Request fulfillment</li>
<li>Problem management</li>
<li>Identity management</li>
<li>Continual Service Improvement</li>
</ul>

<p>For each of the above points, whether you are using ITIL or not, it&rsquo;s
useful to have a conversation. Some of these areas do provide ample
opportunity for automation and for using tooling to minimise the effort
required. But much of this is about designing <em>how</em> you are going to
operate a service throughout it&rsquo;s lifetime.</p>

<h2 id="operations-user-stories">Operations user stories</h2>

<p>One of the other things I published while at The Government was a set of
<a href="https://www.gov.uk/service-manual/operations/web-operations-stories.html">user stories for a web operations
team</a>.
These grew out of work on launching GOV.UK and have had input from
various past colleagues. In hindsight I&rsquo;d probably do somethings
here differently, the stories assume a certain context which isn&rsquo;t explicitly
spelled out for instance. But they have a couple of things going for them in that
they demonstrate how traditional operations activities can be planned out as part
of a more developer-friendly planning approach, and also they are public and
have been tested by more than a single team.</p>

<h2 id="not-everything-is-a-programming-problem">Not everything is a programming problem</h2>

<p>The main point I think is that not everything can be turned into a
programming problem to solve. Automation has it&rsquo;s place, and many manual
processes and practices can benefit from automation. But the wide range
of activities involved in running a non-trivial and often non-ideal
system in production tend to mean making trade-offs and prioritization
decisions frequently. This is where softer skills like arguing for
funding or additional head count, or building a business case for
further work, come into play. Operations management is much more than
systems administration.</p>

<h2 id="further-reading">Further reading</h2>

<p>This is little more than a plea for people to think more about
operations, separate to the more technical aspects of systems
administration. If you&rsquo;re interested in learning more however I would
recommend some good reading material:</p>

<ul>
<li><a href="http://www.itpi.org/the-visible-ops-handbook-review.html">Visible Ops
Handbook</a> -
still an excellent and pragmatic introduction to many of the topics
noted above.</li>
<li><a href="http://shop.oreilly.com/product/0636920033080.do">Designig Delivery</a> -
a bang up-to-date tome covering a range of service design topics.</li>
<li><a href="http://www.basicsm.com/bsm-basic-service-management-book">Basic Service
Management</a> -
a 50 page starter book covering the fundamentals of service
management as generally discussed in more detail elsewhere. A great
starting point.</li>
</ul>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="/2015/12/04/provisioning-droplets-with-puppet/">Provisioning droplets with Puppet</a>
      </h1>
      <span class="post-date">Dec 4, 2015 &middot; 3 minute read
      </span>
      
      

<p>I love <a href="https://www.digitalocean.com/">DigitalOcean</a> for quickly spinning
up machines. I also like managing my infrastructure using Puppet. Enter the
<a href="https://forge.puppetlabs.com/garethr/digitalocean">garethr-digitalocean</a> module.
This currently provides a single Puppet type; <code>droplet</code>.</p>

<p>Lets show a quick example of that, by launching two droplets, called
test-digitalocean and test-digitalocean-1.</p>
<div class="highlight" style="background: #ffffff"><pre style="line-height: 125%"><span></span><span style="color: #336699">droplet</span> { [<span style="color: #dd2200; background-color: #fff0f0">&#39;test-digitalocean&#39;</span>, <span style="color: #dd2200; background-color: #fff0f0">&#39;test-digitalocean-1&#39;</span>]:
  <span style="color: #336699">ensure</span> =&gt; <span style="color: #008800; font-weight: bold">present</span>,
  <span style="color: #336699">region</span> =&gt; <span style="color: #dd2200; background-color: #fff0f0">&#39;lon1&#39;</span>,
  <span style="color: #336699">size</span>   =&gt; <span style="color: #dd2200; background-color: #fff0f0">&#39;512mb&#39;</span>,
  <span style="color: #336699">image</span>  =&gt; <span style="color: #0000DD; font-weight: bold">14169855</span>,
}
</pre></div>

<p>With the above manifest saved as <code>droplets.pp</code> we can run it with:</p>

<pre><code>$ puppet apply --test droplets,pp
</code></pre>

<p>This will ensure those two droplets exist in that region, and have that
size. If they don&rsquo;t exist it will launch droplets using the specified image.
This means we can run the same command again, and rather that create
more instances it will simply report that we currently have those
droplets already.</p>

<h2 id="querying-resources">Querying resources</h2>

<p>Puppet also comes with <code>puppet resource</code>, a handy way of querying the
state of a given resource or type. Running the following will list all
of your droplets, whether you created them using Puppet or not.</p>

<pre><code>$ puppet resource droplet
droplet { 'test-digitalocean':
  ensure              =&gt; 'present',
  backups             =&gt; 'false',
  image               =&gt; '14169855',
  image_slug          =&gt; 'ubuntu-15-10-x64',
  ipv6                =&gt; 'true',
  price_monthly       =&gt; '10.0',
  private_address     =&gt; '10.131.98.186',
  private_networking  =&gt; 'true',
  public_address      =&gt; '178.62.25.100',
  public_address_ipv6 =&gt; '2A03:B0C0:0001:00D0:0000:0000:0090:B001',
  region              =&gt; 'lon1',
  size                =&gt; '1gb',
}
</code></pre>

<h2 id="mutating-resources">Mutating resources</h2>

<p>The type also supports mutating droplets, for instance changing the
size of a droplet if you change the model in Puppet. The API client
doesn&rsquo;t support all possible changes, but you can disable backups, enable
IPv6 and switch on private networking as needed. Here&rsquo;s a quick sample
of the output showing this in action.</p>

<pre><code>Info: Loading facts
Notice: Compiled catalog for gareths-macbook.local in environment production in 0.43 seconds
Info: Applying configuration version '1449225401'
Info: Checking if droplet test-digitalocean exists
Info: Powering off droplet test-digitalocean
Info: Resizing droplet test-digitalocean
Info: Powering up droplet test-digitalocean
Notice: /Stage[main]/Main/Droplet[test-digitalocean]/size: size changed '1gb' to '512mb'
Error: Disabling IPv6 for test-digitalocean is not supported
Error: /Stage[main]/Main/Droplet[test-digitalocean]/ipv6: change from true to false failed: Disabling IPv6 for test-digitalocean is not supported
Error: Disabling private networking for test-digitalocean is not supported
Error: /Stage[main]/Main/Droplet[test-digitalocean]/private_networking: change from true to false failed: Disabling private networking for test-digitalocean is not supported
Info: Checking if droplet test-digitalocean-1 exists
Info: Created new droplet called test-digitalocean-1
Notice: /Stage[main]/Main/Droplet[test-digitalocean-1]/ensure: created
Info: Class[Main]: Unscheduling all events on Class[Main]
Notice: Applied catalog in 60.61 seconds
</code></pre>

<h2 id="but-why">But why?</h2>

<p>Describing your infrastructure at this level in code has several advantages:</p>

<ul>
<li>Having a shared model of your infrastructure in code allows for a discussion
around that model</li>
<li>You can be convident in the model because of the idempotent nature of running
the code</li>
<li>The use of code for this model allows for activities like code review, change
control based on pull requests, unit testing, user created abstrations and more</li>
<li>The use of Puppet means you can use it as above as a command line interface, or
run it every period of time to enfore and report on the state of you infrastructure</li>
<li>Puppet ecosystem tools like PuppetDB, Puppet Board or Puppet Enterprise mean you can
store data over time for later analysis</li>
</ul>

<p>The module also acts as a reasonable example of a simple Puppet type and provider.
If you&rsquo;re interested in extending Puppet for your own services this is hopefully a
good place to start understanding the API.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="/2015/09/20/security-implications-of-unikernels/">Some Security Implication of Unikernels</a>
      </h1>
      <span class="post-date">Sep 20, 2015 &middot; 4 minute read
      </span>
      
      

<p>I was attending the first <a href="http://gotocon.com/goto-london-2015/">GOTO London conference</a> last week, in particlar the <a href="https://www.ruggedsoftware.org/">Rugged</a> Track. One of the topics of conversation that came up was unikernels, and their potential for improving the state of software security. Unikernels are pretty new outside research groups, I’m just lucky enough to live and work in Cambridge where some of that research is happening. The security advantages of unikernels are one of the things that attracted me in the first place. I thought it might be interesting to jot a few of those down for other people interested in security and the future of infrastructure.</p>

<p>As with my <a href="http://www.morethanseven.net/2015/08/21/operating-unikernel-challenges/">last post</a>, it’s worth having a basic understand of Unikernels. I’d recommend reading <a href="http://queue.acm.org/detail.cfm?id=2566628">Unikernels - the rise of the virtual library operating system</a>.</p>

<h2 id="hypervisor">Hypervisor</h2>

<p>Every unikernel is provided the isolation guarantees from a hypervisor. Not only are these guarantees reasonably well understood, they tend to make use of hardware features too. It’s interesting to note that recent container runtime work is heading in this direction too, with ptojects like <a href="https://clearlinux.org/features/clear-containers">Clear Containers from Intel</a>, <a href="https://blogs.vmware.com/cloudnative/introducing-project-bonneville/">Bonneville from VMware</a> and the <a href="https://coreos.com/blog/rkt-0.8-with-new-vm-support/">new stage1 in rkt</a>.</p>

<h2 id="no-user-space">No User Space</h2>

<p>With a typical server OS we have kernel space and user space. Part of the idea here is to ensure the underlying machine doesn’t crash, whatever horrible things people do in user space. But this means <em>you can do horrible things</em>. The unikernel model is similar to the Erlang philosophy of <em>let it crash</em>. You only have kernel space, you entire application resides in it. Most things out of the ordinary are going to crash the kernel. This makes the sort of exploratory testing useful in exploit development harder.</p>

<h2 id="really-immutable-infrastructure">Really Immutable Infrastructure</h2>

<p>People often talk about immutable infrastructure. I’d wager there is more talk than reality however. When you push, people are often not using read-only file systems and retain the capability to login to machines to make ad-hoc changes. What they mean by immutable is that they only change machines at deploy time. This ignores both the fact they have the technical capability to change them anytime, and that an attacker could change them outside that deployment cycle. With unikernel systems there is often just the compiled kernel, you can’t just change files on disk. The defaults force an immutable way of working.</p>

<h2 id="clean-slate-tls">Clean Slate TLS</h2>

<p>As a typical developer or operator you’ve probably learned more than you wanted to know about the OpenSSL source code. It’s not well understood and not likely to be so anytime soon and has some pretty spectacular bugs like <a href="http://heartbleed.com/">Heartbleed</a>. The <a href="https://www.coreinfrastructure.org/">Core Infrastructure Initiative</a> is laudable and will improve things but it’s still a problematic codebase. Functional programming is often regarded as an easier way of writing understandable code. Types are a good thing, especially when it comes to security systems. So a pure <a href="https://mirage.io/blog/introducing-ocaml-tls">OCaml TLS</a> implementation as used by <a href="https://mirage.io/">MirageOS</a> makes sense on lots of levels. Yes this is quite an undertaking, but the <a href="http://amirchaudhry.com/bitcoin-pinata/">bitcoin pinata</a> tests show promise.</p>

<h2 id="formal-proofs">Formal Proofs</h2>

<p>Knowing whether an application really does exactly what you want it to do (and no more) is a hard problem to solve. Unit tests and other form of automated testing help, but are still reliant on people to both write and design the tests. A formal proof system can provide much stronger guarentees of correctness, it’s an approach used in some cases for missing-critical components of <a href="http://cacm.acm.org/magazines/2015/4/184701-how-amazon-web-services-uses-formal-methods/fulltext">Amazon’s AWS</a>. MirageOS is implemented in OCaml. One of the most popular OCaml programmes is <a href="https://coq.inria.fr/">Coq</a>, which just so happens to be a formal proof management system. I’ve not seen many examples yet of this approach, probably due to the effort involved, but the capability is there for building formally specified unikernels. I’d wager a similar thing is possible with Haskell and <a href="https://github.com/GaloisInc/HaLVM">HalVM</a>. Making that easier to do for typical developers could open up much more secure development practices for certain usecases.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="/2015/08/21/operating-unikernel-challenges/">A Discussion of The Operational Challenges With Unikernels</a>
      </h1>
      <span class="post-date">Aug 21, 2015 &middot; 7 minute read
      </span>
      
      

<h2 id="what-are-unikernels">What are Unikernels</h2>

<p>Most of this post assumes a basic understanding of what unikernels are
so I’d recommend reading <a href="http://queue.acm.org/detail.cfm?id=2566628">Unikernels – the rise of the virtual library
operating system</a> before moving
on.</p>

<h2 id="why-are-unikernels-interesting">Why are Unikernels interesting</h2>

<p>As a starting point: complexity. Managing infrastructure, and the
software that runs on it, is too complicated. You can impose
organisational rules to control this complexity (we only deploy on
Debian, we only run JVM applications, the only allowed database is
MySQL) but that limits you in other ways too, and in reality is nearly
always broken somewhere in any non-trivial environment (this appliance
uses Ubuntu, this software is only certified on Windows, PostgreSQL
doesn’t run on the JVM). So you turn to software to manage that
complexity; Puppet or Chef do a great job of allowing configuration
complexity to be managed in code (where you can test it) and Docker
allows for bundles of complexity to be isolated from other bundles of
complexity. But there are still an awful lot of moving parts.</p>

<p>Another reason is the growing realisation that security is important.
Securing systems on the internet is hard. Even though the basics are
broadly understood they are often not implemented, and the people
attempting to compromise systems are smart, well paid and highly
incentivised (basically like you). It’s generally easier to break
something than to build it. Part of this is a numbers game – to run a
reasonable sixed system you might need to run 50 different services, and
install 200 packages on every host. An attacker has to compromise just
one of those to win.</p>

<p>A further reason, if one were needed, is the proliferation of many small
internet connected devices, aka. The Internet of Things. Part of this
relates to the above points about security concerns, but some of it is
simply a matter of managing that many single purpose, low power,
devices. The overhead of a typical general purpose operating system and
application runtime just don’t fit this model.</p>

<p>Enter unikernels. Unikernels actually remove unneeded complexity. You’re
running a hypervisor and the unikernel and that’s it. The unikernel
contains only those libraries that you have specifically required. That
drastically reduces the surface area for attack as well as meaning
you’re running less software, hopefully enough less that your power
needs are reduced too. By specifically requiring individual libraries
you’re also making complexity visible. Rather than using a general
purpose operating system with it’s 100s of packages and millions of
lines of code you are at least choosing what to include.</p>

<h2 id="operational-challenges">Operational challenges</h2>

<p>While I think some part of the future looks like unikernels their are
some large operational challenges to overcome before they break out of
very specific niches or research projects. Note that</p>

<p>there are architectural and software development challenges as well, I
just happen to think they’re easier to deal with.</p>

<h3 id="development-environment">Development environment</h3>

<p>There are a few properties of a development environment that I think are
essential to modern development; development/production parity being one
of the most important. Tools like Vagrant, and a move towards
infrastructure as code, and more recently Docker have made great strides
here in the past several years. The different unikernel implementations
are generally based on lesser known software stacks (Haskell, OCaml,
Erlang, etc) so some of this is familiarity. But what does
development/production partity mean for a unikernel based system? We’re
not just talking about the individual unikernel here either – how do I
deploy unikernels? How do I compose several unikernels together to build
an application? What does a Continuous integration or deployment
pipeline look like? In my view the unikernel movement should focus some
efforts here. Not only will this make it easier for people to get
started, but having strong opinions early will allow the nascent
community to solve the problem together, rather than everyone solving it
just-in-time for themselves.</p>

<h3 id="managing-the-hypervisor">Managing the hypervisor</h3>

<p>I’d argue today most developers don’t spent much time directly working
with hypervisors. Either you’re running on an in-house VMware, KVM or
Xen install with some (hopefully self-service, automated) provisioning
mechanism in place or you’re using a public cloud like AWS, Azure, etc.
The current generation of unikernel systems mainly target Xen. I think
in the short term at least this means getting to know the hypervisor.
Xen is solid software, but I don’t see a great deal of automation around
it – say well maintained Puppet modules, API clients or a Terraform
provider. In the long term we’ll hopefully have higher level interfaces,
but in the short term efforts here would lower the barrier to entry
considerably.</p>

<h4 id="double-down-on-aws">Double down on AWS</h4>

<p>Given the above, and given the ubiquity of EC2 (which is based on Xen)
it might be wise to build up first-class tools around using EC2 as a
target environment for unikernel deployments. EC2 supports custom
kernels, but these require a number of convoluted steps that could be
automated away (note that I’m talking about more than just a shell
script here). Also what are the best practices around autoscaling groups
andunikernels? Or VPC networks and unikernels?</p>

<h3 id="the-network">The network</h3>

<p>With the explosion in containers and microservices it’s becoming clearer
(if it wasn’t already) how important the network is. By removing the
operating system we remove things like host firewalls and the new breed
of overlay networks. At the same time if we are to tap the dynamic
potential of unikernels we’ll need a similarly dynamic and automatable
network. Maybe this becomes more of an application concern, with
services communicating via other services which act as firewalls and
intelligent proxies, but that still leaves the underlying network to be
managed.</p>

<h3 id="debugging">Debugging</h3>

<p>However much testing you do beforehand you’ll still likely end up with
problems in production, and as you scale up you’ll hit issues that you
simply can’t recreate outside the live environment. This is were good
debugging capabilities come in. While general purpose operating systems
might be complex they are well know, and tools like ps, top, free, ping,
telnet, netcat, dtrace, etc. are commonly used by anyone debugging
systems. Note that in many cases you’re debugging a combination of
systems; is the performance issue an application problem, a network
problem, a storage problem or some interesting combination of several
facters?</p>

<p>By removing the general purpose operating system, unikernel based
environments remove most of the current debugging tools at the same
time. Part of this Is good application development hygiene (logs,
metrics and status endpoints for instance), but what about the more
interactive debugging practices? What does debugging a system based on
unikernels look like?</p>

<h3 id="orchestration">Orchestration</h3>

<p>The word may be overloaded but the need to arrange and manage a number
of components that make up a larger system is a real need. This might be
something like Docker&rsquo;s Compose file or <a href="https://brooklyn.incubator.apache.org/learnmore/blueprint-tour.html">Brooklyn&rsquo;s
Blueprints</a>,
or it could be something more akin to the APIs from Cloud Foundry,
Kubernetes or Mesos. Testing some of these models with unikernel based systems
will be an interesting test of how coupled to containers the existing models are.
The lack of legacy again opens up the potential to come up with a truly
modern alternative here too.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Unless you’re in an environment where security is your number 1 concern
then the current state of Unikernels probably means choosing to adopt
them now is a little bleeding edge. But I think that will change over
time as the various projects mature and address some of the issues
described above. In the meantime I’d love to see more discussion of some
of the operational challenges. I think talking about the needs of
operators at this early stage should make the resulting ecosystems more
robust whsen it comes to future production deployments.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="/2015/08/20/puppet-module-skeleton-updates/">Update to Puppet Module Skeleton</a>
      </h1>
      <span class="post-date">Aug 20, 2015 &middot; 2 minute read
      </span>
      
      <p>Being on holiday last week meant I had a little time for some gardening
of open source projects and I decided to update
<a href="https://www.github.com/garethr/puppet-module-skeleton">puppet-module-skeleton</a>
with some new opinions.</p>

<p>The skeleton is a replacement for the default module skeleton that ships
with Puppet and is used by puppet module generate. Unlike the default
skeleton this one is super-opinionated. It comes bundled with lots of
testing tools, suggestions for documentation, integration with <a href="http://travis-ci.org">Travis
CI</a>, module coverage reports and more.</p>

<p>Updates in the latest version include:</p>

<ul>
<li>Support for Puppet 4 paths</li>
<li>The addition of Rubocop, which enforces parts of the Ruby style guide</li>
<li>Adding a number of Puppet Lint plugins</li>
<li>Allow installing various Puppet versions during integration tests</li>
</ul>

<p>I also fixed a few reported bugs and extended the test matrix to test
across a range of Puppet and Ruby combinations.</p>

<p>The skeleton is intended to help people with a basic understanding of
Puppet write better modules, without having to setup everything
themselves. You don’t have to agree with all the options to make use of
the skeleton as it’s simple enough to delete a few files once you
generate your new module. But a working out-of-the-box beaker install,
and the ability to automatically run unit tests when files change are
patterns worth adopting for most module developers I think.</p>

<p>If anyone has any suggestions for extra tools, or changes to the
skeleton itself, let me know.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="/2015/05/19/information-security-reading-list/">Information Security Reading List</a>
      </h1>
      <span class="post-date">May 19, 2015 &middot; 3 minute read
      </span>
      
      

<p>I read quite a bit (probably a book a week or so) and one of the topics
I&rsquo;ve been reading on for a while is information security. In a recent
conversation someone asked for some book suggestions, so I thought I&rsquo;d
write that up in a blog post rather than an email.</p>

<p>Most of this list isn&rsquo;t particularly technical. It&rsquo;s not a developers
list of software engineering tomes. If you&rsquo;re a developer or operator
then I&rsquo;d recommend reading some of the more policy or journalistic
pieces as well for context. And if you&rsquo;re just interested in the topic
but nor particularly technical I&rsquo;d skip the security engineering
suggestions.</p>

<p>Note that I make no claims about this being a particularly balanced
list, it&rsquo;s biased towards what I find interesting to read. Hopefully
you&rsquo;ll find it interesting too.</p>

<h2 id="journalism">Journalism</h2>

<p>Understanding why Information Security is important tends to require
some context. The following books provide that, with detailed real-world
stories of criminal and government activities.</p>

<ul>
<li><a href="http://www.amazon.co.uk/The-Dark-Net-Jamie-Bartlett/dp/0434023159">The Dark Net</a> - Jamie Bartlett - an excellent personal tale of
investigating the hidden side of the internet.</li>
<li><a href="http://www.amazon.co.uk/Spam-Nation-Organized-Cybercrime-Epidemic-ebook/dp/B00L5QGBL0">Spam Nation</a> - Brian Krebs - everything you wanted to know about how
and why Spam works.</li>
<li><a href="http://www.amazon.co.uk/Countdown-Zero-Day-Stuxnet-Digital/dp/077043617X">Countdown to Zero Day</a> - Kim Zetter - a detailed and fast paced
description of the Stuxnet attack, and it&rsquo;s implications.</li>
<li><a href="http://www.amazon.co.uk/Future-Crimes-Everything-Connected-Vulnerable/dp/0385539002">Future Crimes</a> - Marc Goodman - a focus on the criminal
possibilities of the modern internet and the internet of things.</li>
<li><a href="http://www.amazon.co.uk/Worm-The-First-Digital-World/dp/1611855845">Worm</a> - Mark Bowden - similar to the excellent tale of Stuxnet
above, this is the story of Conficker and how it was discovered</li>
</ul>

<h1 id="policy-and-context">Policy and context</h1>

<p>These books are focused more on government policy and nation state
threats, and the debate about the rules of war and the internet.</p>

<ul>
<li><a href="http://www.amazon.co.uk/Cyber-War-Threat-National-Security/dp/0061962244">Cyber War</a> - Richard Clarke - probably the best description of what
cyber war is and isn&rsquo;t, and some of the geopolitical problems
emerging.</li>
<li><a href="http://www.amazon.co.uk/Cyber-War-Will-Take-Place/dp/1849042802">Cyber War Will Not Take Place</a> - Thomas Rid - a good counter to the
above book, with lots more detailed discussion of policy and definition.</li>
<li><a href="http://www.amazon.co.uk/Inside-Cyber-Warfare-Mapping-Underworld/dp/1449310044">Inside Cyber Warfare</a> - Jeffrey Carr - really just a run through of
current threats, especially organised crime.</li>
</ul>

<h1 id="security-engineering">Security engineering</h1>

<ul>
<li><a href="http://www.cl.cam.ac.uk/~rja14/book.html">Security Engineering</a> - Ross Anderson - highly technical and quite
epic, but definitely the best security engineering book around.</li>
<li><a href="http://www.amazon.co.uk/Threat-Modeling-Designing-Adam-Shostack/dp/1118809998">Threat Modelling</a> - Adam Shostack - details descriptions of how and
why to conduct threat moddelling, with lots of examples.</li>
<li><a href="http://www.amazon.co.uk/Data-Driven-Security-Visualization-Dashboards/dp/1118793722">Data Driven Security</a> - Jay Jacobs and Bob Rudis - nice examples,
including code samples, of applying data and statistics tools and
practices to security problems.</li>
<li><a href="http://www.amazon.co.uk/Cloud-Security-Privacy-Enterprise-Perspective/dp/0596802765">Cloud Security and Privacy</a> - Tim Mather, Subra Kumaraswamy, Shahed
Latif - a good book to read for anyone working in AWS, Azure or similar.
Good discussion of concerns and compliance approaches in third party
environments.</li>
<li><a href="http://www.amazon.co.uk/The-Tangled-Web-Securing-Applications/dp/1593273886">The Tangled Web</a> - Michal Zalewski - everything you ever wanted to
know about the browser security model</li>
<li><a href="http://www.amazon.co.uk/Silence-Wire-Passive-Reconnaissance-Indirect/dp/1593270461">Silence on the Wire</a> - Michal Zalewski - described as a field guide
to passive reconnaissance and indirect attacks. Good for starting to
think about non-obvious security threats</li>
</ul>

<h1 id="on-my-reading-list">On my reading list</h1>

<p>I&rsquo;ve not read these books yet so can&rsquo;t recommend them as such, but they
both look good additions to the list above.</p>

<ul>
<li><a href="http://www.amazon.co.uk/Data-Goliath-Bruce-Schneier/dp/0393244814">Data and Goliath</a> - Bruce Schneier - a look at the large scale data
collection programmes of governments and their implications for
everyone.</li>
<li><a href="http://www.amazon.co.uk/Black-Code-Ronald-J-Deibert/dp/0771025351">Black Code</a> - Ronald J. Deibert - the story of the Citizen Lab
and it&rsquo;s front line cyber researchers</li>
</ul>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="/2015/05/09/acceptance-testing-mirageos/">Acceptance testing MirageOS installs</a>
      </h1>
      <span class="post-date">May 9, 2015 &middot; 2 minute read
      </span>
      
      

<p>I&rsquo;m pretty interested in <a href="http://openmirage.org/">MirageOS</a> at the
moment. Partly because I find the idea behind unikernels interesting and
partly because I keep bumping into the nice folks <a href="http://www.cl.cam.ac.uk/projects/ocamllabs/">OCaml
Labs</a> in Cambridge.</p>

<p>In order to write and build your MirageOS unikernel application you need
an OCaml development environment. Although this is
<a href="http://openmirage.org/wiki/install">documented</a> I wanted something a
little more repeatable. I also found and reported a few bugs in the
documentation which got me thinking about acceptance testing. I&rsquo;m not
(yet) an OCaml programmer, but infrastructure automation and testing I
can do.</p>

<h2 id="into-puppet">Into Puppet</h2>

<p>I started out writing a Puppet module to install and manage everything,
which is now available on
<a href="https://github.com/garethr/garethr-mirageos">GitHub</a> and on the
<a href="https://forge.puppetlabs.com/garethr/mirageos">Forge</a>.</p>

<p>This lets you do something like the following, and have a fully working
MirageOS setup on Ubuntu 12.04 or 14.04.</p>
<div class="highlight" style="background: #ffffff"><pre style="line-height: 125%"><span></span><span style="color: #008800; font-weight: bold">class</span> { <span style="color: #dd2200; background-color: #fff0f0">&#39;mirageos&#39;</span>:
  <span style="color: #008800; font-weight: bold">user</span>      =&gt; <span style="color: #dd2200; background-color: #fff0f0">&#39;vagrant&#39;</span>,
  <span style="color: #336699">opam_root</span> =&gt; <span style="color: #dd2200; background-color: #fff0f0">&#39;/home/vagrant/.opam&#39;</span>,
}
</pre></div>

<p>Given time, inclination or pull requests I&rsquo;ll add support for other
operating systems in the future.</p>

<h2 id="but-how-do-you-know-it-works">But how do you know it works?</h2>

<p>The module has a small unit test suite, but it&rsquo;s nice to know test the
actual running of Puppet and installation of the software. For this I&rsquo;ve
used <a href="http://kitchen.ci/">Test Kitchen</a> and
<a href="http://serverspec.org/">ServerSpec</a>. This allows for spinning up 2
virtual machines (one for each supported operating system), applying the
Puppet manifest and then making some assertions:</p>

<script src="//gist.github.com/garethr/a8d090b5d7f7a190f7d9.js"></script>

<p>The above is simply checking whether certain packages are installed, the
PPA is setup correctly and whether <code>mirage</code> and <code>opam</code> can be executed
cleanly.</p>

<h2 id="can-it-produce-a-working-unikernel">Can it produce a working unikernel?</h2>

<p>The above tells us whether the installation worked, but not whether the
resulting software allows us to build MirageOS unikernels. For this I
used <a href="https://github.com/sstephenson/bats">Bats</a> running in the same
Test Kitchen setup.</p>

<script src="//gist.github.com/garethr/191c4c0676b471f9b986.js"></script>

<p>The above configures and builds a simple HTTP server unikernel, and then
checks that when run it returns the expected response on the correct
port.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I like the separation of concerns above. I can use the Puppet code
without the test code, or even swap the Puppet code out for a shell
script if I wanted. I could also run the serverspec tests anywhere I
want to check state, which is the reason for separating those tests from
the one&rsquo;s building and running a unikernel. Overall the tool chain for ad-hoc
infrastructure testing (quick mention of
<a href="http://infrataster.net/">Infrataster</a> too) is really quite powerful and
approachable. I&rsquo;d love to see more software ship with a user-facing test
suite for people to verify their installation works.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="/2015/01/02/automating-windows-development-environments/">Automating windows development environments</a>
      </h1>
      <span class="post-date">Jan 2, 2015 &middot; 1 minute read
      </span>
      
      <p>My job at Puppet Labs has given me an excuse to take a closer look at
the advancements in Windows automation, in particular <a href="https://chocolatey.org/">Chocolatey</a>
and <a href="http://boxstarter.org/">BoxStarter</a>. The following is very much a work
in progress but it&rsquo;s hopefully useful for a few things:</p>

<ul>
<li>If like me you&rsquo;ve mainly been doing non-Windows development for a
while it&rsquo;s interesting to see what is possible</li>
<li>If you&rsquo;re starting out with infrastructure development on Windows the
following could be a good starting place</li>
<li>if you&rsquo;re an experienced Windows pro then you can let me know of any
improvements</li>
</ul>

<p>All that&rsquo;s needed is to run the following from a CMD or Powershell
prompt on a new Windows machine (you can also visit the URL in Internet
Explorer if you prefer).</p>

<pre><code>START http://boxstarter.org/package/nr/url?https://gist.githubusercontent.com/garethr/a1838aa68355a0766de4/raw/d92b41ee9dcad68c079d24c64bac7d1d27cf37c7/garethr.ps1
</code></pre>

<p>This launches BoxStarter, which executes the following code:</p>

<script src="//gist.github.com/garethr/a1838aa68355a0766de4.js"></script>

<p>This takes a while as it runs Windows update and repeatedly reboots the
machine. But once completed you&rsquo;ll have the listed software installed
and configured on a newly up-to-date Windows machine.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="/2014/10/28/docker-puppet-shared-volumes/">Docker, Puppet and shared volumes</a>
      </h1>
      <span class="post-date">Oct 28, 2014 &middot; 4 minute read
      </span>
      
      

<p>During one of the openspace sessions at Devopsdays we talked about docker and configuration management,
and one of the things we touched on was using dockers shared volumes support. This is easier to explain
with an example.</p>

<p>First, lets create a docker image to run puppet. I&rsquo;m also installing r10k for managing third party
modules.</p>

<h2 id="docker">Docker</h2>

<pre><code>FROM ubuntu:trusty

RUN apt-get update -q
RUN apt-get install -qy wget
RUN wget http://apt.puppetlabs.com/puppetlabs-release-trusty.deb
RUN dpkg -i puppetlabs-release-trusty.deb
RUN apt-get update

RUN apt-get install -y puppet ruby1.9.3 build-essential git-core
RUN echo &quot;gem: --no-ri --no-rdoc&quot; &gt; ~/.gemrc
RUN gem install r10k
</code></pre>

<p>Lets build that and tag it locally. Feel free to use whatever name you like here.</p>

<pre><code>docker build -t garethr/puppet .
</code></pre>

<p>Lets now use that image as a base for another image.</p>

<pre><code>FROM garethr/puppet

RUN mkdir /etc/shared
ADD Puppetfile /
RUN r10k puppetfile check
RUN r10k puppetfile install
ADD init.pp /
CMD [&quot;puppet&quot;, &quot;apply&quot;, &quot;--modulepath=/modules&quot;, &quot;/init.pp&quot;,&quot;--verbose&quot;, &quot;--show_diff&quot;]
</code></pre>

<p>This image will be used to create containers that we intend to run. Here we&rsquo;re including a
Puppetfile (a list of module dependencies) and then running r10k to download those dependencies.
Finally we add a simple puppetfile (this would likely be an entire manifests directory in most cases).
The final line means that when we run a container based on this image it will run puppet and then exit.</p>

<p>Again lets build the image and tag it.</p>

<pre><code>docker build -t garethr/puppetshared .
</code></pre>

<p>Just as a demo, here&rsquo;s a sample <code>Puppetfile</code> which includes the puppetlabs stdlib module.</p>

<h2 id="puppet">Puppet</h2>

<pre><code>mod 'puppetlabs/stdlib'
</code></pre>

<p>And again as an example here&rsquo;s a simple puppet <code>init.pp</code> file. All we&rsquo;re doing is creating a file
at a specific location.</p>

<pre><code>file { '/etc/shared/client':
  ensure =&gt; directory,
}

file { '/etc/shared/client/apache.conf':
  ensure  =&gt; present,
  content =&gt; &quot;not a real config file&quot;,
}
</code></pre>

<h2 id="fig">Fig</h2>

<p><a href="http://fig.sh">Fig</a> is a tool to declare container types in a text file, and then run and manage
them from a simple CLI. We could do all this with straigh docker calls too.</p>
<div class="highlight" style="background: #ffffff"><pre style="line-height: 125%"><span></span>master:
  image: garethr/puppetshared
  volumes:
    - /etc/shared:/etc/shared:rw

client:
  image: ubuntu:trusty
  volumes:
    - /etc/shared/client:/etc/:ro
  command: <span style="color: #dd2200; background-color: #fff0f0">&#39;/bin/sh</span><span style="color: #336699"> </span><span style="color: #dd2200; background-color: #fff0f0">-c</span><span style="color: #336699"> </span><span style="color: #dd2200; background-color: #fff0f0">&quot;while</span><span style="color: #336699"> </span><span style="color: #dd2200; background-color: #fff0f0">true;</span><span style="color: #336699"> </span><span style="color: #dd2200; background-color: #fff0f0">do</span><span style="color: #336699"> </span><span style="color: #dd2200; background-color: #fff0f0">echo</span><span style="color: #336699"> </span><span style="color: #dd2200; background-color: #fff0f0">hello</span><span style="color: #336699"> </span><span style="color: #dd2200; background-color: #fff0f0">world;</span><span style="color: #336699"> </span><span style="color: #dd2200; background-color: #fff0f0">sleep</span><span style="color: #336699"> </span><span style="color: #dd2200; background-color: #fff0f0">1;</span><span style="color: #336699"> </span><span style="color: #dd2200; background-color: #fff0f0">done&quot;&#39;</span>
</pre></div>

<p>The important part of the above is the volumes lines. What we&rsquo;re doing here is:</p>

<ul>
<li>Sharing the <code>/etc/shared</code> directory on the host with the container called master. The container will be able to write to the host filesystem.</li>
<li>Sharing a subdirectory of of <code>/etc/shared</code> with the client container. The client can only read this information.</li>
</ul>

<p>Note the client container here isn&rsquo;t running Puppet. Here it&rsquo;s just running sleep in a loop to simulate a long running process like
your custom application.</p>

<p>Let&rsquo;s run the master. Note that this will run puppet and then exit. But with the above manifest it will create
a config file on the host.</p>

<pre><code>fig run master
</code></pre>

<p>Then run the client. This won&rsquo;t exit and should just print <code>hello world</code> to stdout.</p>

<pre><code>fig run client
</code></pre>

<p>Docker 1.3 adds the handy exec command, which allows for one-off commands to be executed within a running container.
Lets use that to see our new config file.</p>

<pre><code>docker exec puppetshared_client_run_1 cat /etc/apache.conf
</code></pre>

<p>This should output the contents of the file we created by running the master container.</p>

<h2 id="why">Why?</h2>

<p>This is obviously a very simple example but I think it&rsquo;s interesting for a few reasons.</p>

<ul>
<li>We have completely separated our code (in the container) from the configuration</li>
<li>We get to use familiar tools for managing the configuration in a familiar way</li>
</ul>

<p>It also raises a few problems:</p>

<ul>
<li>The host needs to know what types of container are going to run on it, in order to have the correct configuration. If you&rsquo;re using <a href="https://forge.puppetlabs.com/garethr/docker">Puppet module</a> then this is simple enough to solve.</li>
<li>The host ends up with all of the configuration for all the containers in one place, you could also do things with encrypting the data and having the relevant keys in one image and not others. Given how if you&rsquo;re on the host you own the container anyway this isn&rsquo;t as odd as it sounds.</li>
<li>We&rsquo;re just demonstrating files here, but if we change our manifest and rerun the puppet container then we change the config files. But depending on the application it  won&rsquo;t pick that up unless we restart it or create a new container.</li>
</ul>

<p>Given enough time I may try build a reference implementation using this approach, anyone with ideas about that let me know.</p>

<p>This post was inspired by a conversation with <a href="https://twitter.com/kelseyhightower">Kelsey</a> and <a href="http://twitter.com/botchagalupe">John</a>, thanks guys.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="/2014/10/12/using-puppet-with-key-value-config-stores/">Using Puppet with key/value config stores</a>
      </h1>
      <span class="post-date">Oct 12, 2014 &middot; 2 minute read
      </span>
      
      <p>I like the central idea behind storing configuration in something like
<a href="https://github.com/coreos/etcd">Etcd</a> rather than lots of files on lots
of disks, but a few challenges still remain. Things that spring to mind
are:</p>

<ul>
<li>Are all your passwords now available to all of your nodes?</li>
<li>How do I know when configuration changed and who changed it?</li>
</ul>

<p>I&rsquo;ll leave the first of those for today (although have a look at
<a href="http://www.conjur.net/">Conjur</a> as one approach to this). For the second,
I&rsquo;m quite fond of plain text, pull requests and a well tested deployment
pipeline. Before Etcd (or <a href="http://www.consul.io/">Consul</a> or similar) you
would probably have values in Hiera or Data Bags or similar and inject them
into files on hosts using your configuration management tool of choice. So
lets just do the same with our new-fangled distributed configuration store.</p>
<div class="highlight" style="background: #ffffff"><pre style="line-height: 125%"><span></span><span style="color: #336699">key_value_config</span> { <span style="color: #dd2200; background-color: #fff0f0">&#39;/foo&#39;</span>:
  <span style="color: #336699">ensure</span>   =&gt; <span style="color: #008800; font-weight: bold">present</span>,
  <span style="color: #336699">provider</span> =&gt; <span style="color: #336699">etcd</span>,
  <span style="color: #336699">value</span>    =&gt; <span style="color: #dd2200; background-color: #fff0f0">&#39;bar&#39;</span>,
}
</pre></div>

<p>Say you wanted to switch over to using Consul instead? Just switch the provider.</p>
<div class="highlight" style="background: #ffffff"><pre style="line-height: 125%"><span></span><span style="color: #336699">key_value_config</span> { <span style="color: #dd2200; background-color: #fff0f0">&#39;/foo&#39;</span>:
  <span style="color: #336699">ensure</span>   =&gt; <span style="color: #008800; font-weight: bold">present</span>,
  <span style="color: #336699">provider</span> =&gt; <span style="color: #336699">consul</span>,
  <span style="color: #336699">value</span>    =&gt; <span style="color: #dd2200; background-color: #fff0f0">&#39;bar&#39;</span>,
}
</pre></div>

<p>You&rsquo;d probably move all of that out into something like hiera, and then generate
the above resources, but you get the idea.</p>
<div class="highlight" style="background: #ffffff"><pre style="line-height: 125%"><span></span>etcd_values:
  foo: bar
</pre></div>

<p>The above is implemented in a very simple
<a href="https://github.com/garethr/garethr-key_value_config">proof of concept Puppet module</a>.
Anyone with any feedback please do let me know.</p>

      
    </div>
    
    
    
    <ul class="pagination">
        
        <li>
            <a href="/" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
        </li>
        
        <li
        >
        <a href="/" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
        </li>
        
        <li
        ><a href="/">1</a></li>
        
        <li
        class="active"><a href="/page/2/">2</a></li>
        
        <li
        ><a href="/page/3/">3</a></li>
        
        <li
        ><a href="/page/4/">4</a></li>
        
        <li
        ><a href="/page/5/">5</a></li>
        
        <li
        ><a href="/page/6/">6</a></li>
        
        <li
        ><a href="/page/7/">7</a></li>
        
        <li
        ><a href="/page/8/">8</a></li>
        
        <li
        ><a href="/page/9/">9</a></li>
        
        <li
        ><a href="/page/10/">10</a></li>
        
        <li
        ><a href="/page/11/">11</a></li>
        
        <li
        ><a href="/page/12/">12</a></li>
        
        <li
        ><a href="/page/13/">13</a></li>
        
        <li
        ><a href="/page/14/">14</a></li>
        
        <li
        ><a href="/page/15/">15</a></li>
        
        <li
        ><a href="/page/16/">16</a></li>
        
        <li
        ><a href="/page/17/">17</a></li>
        
        <li
        ><a href="/page/18/">18</a></li>
        
        <li
        ><a href="/page/19/">19</a></li>
        
        <li
        ><a href="/page/20/">20</a></li>
        
        <li
        ><a href="/page/21/">21</a></li>
        
        <li
        ><a href="/page/22/">22</a></li>
        
        <li
        ><a href="/page/23/">23</a></li>
        
        <li
        ><a href="/page/24/">24</a></li>
        
        <li
        ><a href="/page/25/">25</a></li>
        
        <li
        ><a href="/page/26/">26</a></li>
        
        <li
        ><a href="/page/27/">27</a></li>
        
        <li
        ><a href="/page/28/">28</a></li>
        
        <li
        ><a href="/page/29/">29</a></li>
        
        <li
        ><a href="/page/30/">30</a></li>
        
        <li
        ><a href="/page/31/">31</a></li>
        
        <li
        ><a href="/page/32/">32</a></li>
        
        <li
        ><a href="/page/33/">33</a></li>
        
        <li
        ><a href="/page/34/">34</a></li>
        
        <li
        ><a href="/page/35/">35</a></li>
        
        <li
        ><a href="/page/36/">36</a></li>
        
        <li
        ><a href="/page/37/">37</a></li>
        
        <li
        ><a href="/page/38/">38</a></li>
        
        <li
        ><a href="/page/39/">39</a></li>
        
        <li
        ><a href="/page/40/">40</a></li>
        
        <li
        ><a href="/page/41/">41</a></li>
        
        <li
        ><a href="/page/42/">42</a></li>
        
        <li
        >
        <a href="/page/3/" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
        </li>
        
        <li>
            <a href="/page/42/" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
        </li>
        
    </ul>
    
  </div>
</div>



</body>
</html>

